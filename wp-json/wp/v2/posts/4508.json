{"id":4508,"date":"2023-07-24T20:32:32","date_gmt":"2023-07-24T15:02:32","guid":{"rendered":"https:\/\/newwebsite.nestdigital.com\/?p=4508"},"modified":"2023-08-12T18:14:04","modified_gmt":"2023-08-12T12:44:04","slug":"detecting-car-damage-using-yolo","status":"publish","type":"post","link":"https:\/\/nestdigital.com\/blogs\/detecting-car-damage-using-yolo\/","title":{"rendered":"Detecting Car Damage using YOLO"},"content":{"rendered":"\n<p id=\"be2d\">You might have heard of ADAS (Advanced driver assistance systems) in many cars nowadays, which are smart enough to detect the human in front of the car and apply brakes automatically. Have you thought what is the technology behind that? Leading car Manufacturers have stepped in to integrate ADAS into their cars. Existing ADAS technologies operate on visual cameras, RADARs, and LiDARs for the object detection. ADAS mainly depends on features such as high speed, high accuracy, low cost, and low power consumption.<\/p>\n\n\n\n<p id=\"8b38\">In this blog, we will talk about the real-time Object Detection technique YOLO (You Look Only Once). Not only that, I will share how YOLO can help us detect damage in the Car.<\/p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"0ecb\">What is YOLO?<\/h2>\n\n\n\n<p id=\"b84a\">YOLO or You Look Only Once is a popular Object Detection technique. That means, it performs two tasks&nbsp;<strong>Object Classification<\/strong>&nbsp;&amp;&nbsp;<strong>Object Localization.<\/strong>Since, there are two tasks many Object detection algorithms such as R-CNN, Fast RCNN, Faster RCNN are using two-step or two neural networks. But as the name itself defines, YOLO \u2014 looks at the entire image at once, and only once which allows it to capture the context of detected objects. Due to the single network, it is much faster than other object detection algorithms and can perform real-time detection at 45 frames per second.<\/p>\n\n\n\n<p id=\"4e73\">There are various versions of YOLO you will find out, the first version was released in 2016, and version 3 which is discussed here was created in 2018. The official successors of YOLOv3 are YOLOv4, and the newly released YOLOv7, which is the current state-of-the-art object detector in 2022.<\/p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"45cc\">YOLOv1 Architecture<\/h2>\n\n\n\n<figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https:\/\/miro.medium.com\/v2\/resize:fit:1400\/1*9ZlcXLNrbm_3WRhq_vPqoA.png\" alt=\"\"\/><figcaption class=\"wp-element-caption\">YOLO architecture from&nbsp;<a href=\"https:\/\/arxiv.org\/pdf\/1506.02640.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">original paper&nbsp;<\/a>modified by Author<\/figcaption><\/figure>\n\n\n\n<p id=\"e348\">The architecture works as follows:<\/p>\n\n\n\n<ul>\n<li>Resizing the Input image to 448 x 448 before going through the convolutional network.<\/li>\n\n\n\n<li>In total, it contains 24 convolutional layers followed by 2 fully connected layers.<\/li>\n\n\n\n<li>Uses 1&#215;1 convolution layers to reduce the channels, followed by 3&#215;3 convolutional.<\/li>\n\n\n\n<li>Softmax is used for class predictions.<\/li>\n<\/ul>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"93b0\">Difference between YOLOv1 and YOLOv3 Architecture<\/h2>\n\n\n\n<ul>\n<li>YOLOv3 uses 53 Convolutional layers and skip connections.<\/li>\n\n\n\n<li>YOLOv3 uses logistic regression with binary cross-entropy loss. Since, there is possibility two classes(men &amp; Person) are there for a single box and using softmax imposes that each box has exactly one class which is mostly not the case.<\/li>\n<\/ul>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"aca7\">How YOLO works?<\/h2>\n\n\n\n<p id=\"7c18\">Now you have understood the architecture, let&#8217;s try to understand how the YOLO algorithm works actually.<\/p>\n\n\n\n<p id=\"6bf5\">\u201c<em>Let\u2019s suppose we have built a YOLO Model to detect the damage in the car.<\/em><\/p>\n\n\n\n<p id=\"bb95\"><em>You will understand the whole process of how YOLO performs object detection; how to get image (B) from image (A)\u201d<\/em><\/p>\n\n\n\n<figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https:\/\/miro.medium.com\/v2\/resize:fit:1322\/1*3USXPnvUlUvtm8iiUfxZjg.png\" alt=\"\"\/><\/figure>\n\n\n\n<p id=\"c5ef\">YOLO Algorithm works on the following four approaches:<\/p>\n\n\n\n<ul>\n<li><strong>Residual blocks<\/strong><\/li>\n\n\n\n<li><strong>Bonding box regression<\/strong><\/li>\n\n\n\n<li><strong>Intersection over Union (IoU)<\/strong><\/li>\n\n\n\n<li><strong>Non-Maximum supression<\/strong><\/li>\n<\/ul>\n\n\n\n<ol>\n<li><strong>Residual Blocks<\/strong><\/li>\n<\/ol>\n\n\n\n<p id=\"cc92\">YOLO works on the idea of segmentation of the image into smaller parts. The image is divided into square grid of size SxS like:<\/p>\n\n\n\n<figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https:\/\/miro.medium.com\/v2\/resize:fit:908\/1*0302JPOs_gq3CEERZL32Fg.png\" alt=\"\"\/><\/figure>\n\n\n\n<p id=\"feb4\">The cell in which the center of the object is the cell responsible for detecting that object.<\/p>\n\n\n\n<p id=\"11cf\"><strong>2. Bonding box Regression<\/strong><\/p>\n\n\n\n<p id=\"97c9\">The next step is to determine the bonding boxes, each cell can have B bounding boxes. The value of B can be determined while creating model architecture.<\/p>\n\n\n\n<figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https:\/\/miro.medium.com\/v2\/resize:fit:1032\/1*ONX754OSnxCnBp-Yy_el8A.png\" alt=\"\"\/><\/figure>\n\n\n\n<p id=\"a7e3\">YOLO determines the values of these bonding boxes using a single regression module. Each of the bonding boxes are made up of 5 numbers + N class scores: confidence of box, x position, y position, width, height, and class score. Here confidence score will be between 0.0 and 1.0 with 0.0 means that there is no object in that cell and 1.0 means model is certain there is an object. x and y are the center of the predicted bounding box and width &amp; height are the fractions relative to the image size. Class score are confidence of particular class.<\/p>\n\n\n\n<p id=\"65ac\"><strong>3. Intersection over Union (IoU)<\/strong><\/p>\n\n\n\n<p id=\"8ca6\">Many times, a single image can have multiple boxes for a single object. IoU helps to find the most relevant box. IoU values lies between 0 and 1. IoU is the area of the Intersection of predicted and ground truth boxes divided by the area of the Union of predicted and ground truth boxes.<\/p>\n\n\n\n<ul>\n<li>The user can define the threshold value for IoU such as 0.5.<\/li>\n\n\n\n<li>Thereafter, it ignores boxes with IoU \u2264 0.5 and only considers boxes with IoU &gt; 0.5.<\/li>\n<\/ul>\n\n\n\n<p id=\"142e\"><strong>4. Non-Max Supression<\/strong><\/p>\n\n\n\n<p id=\"ef13\">Even after applying the IoU technique, there is a possibility that there are more than one boxes for an object. For dealing with that we choose the box with the highest value of confidence score of detection and suppress the Non-max values.<\/p>\n\n\n\n<p id=\"e5c2\">Therefore, the model finally predicts&nbsp;<strong><em>S \u00d7 S \u00d7 (C + B&nbsp;<\/em>\u2217 5<em>).<\/em><\/strong><\/p>\n\n\n\n<p id=\"cc48\">S = No of grids<\/p>\n\n\n\n<p id=\"64ef\">C = Number of classes<\/p>\n\n\n\n<p id=\"9ace\">B= Number of bonding boxes per grid cell.<\/p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"91fc\">YOLO Training \u2014 Damage detection<\/h2>\n\n\n\n<p id=\"af52\">For the training of damage detection in cars, we have used the dataset available on Kaggle:&nbsp;<a href=\"https:\/\/www.kaggle.com\/datasets\/lplenka\/coco-car-damage-detection-dataset\" rel=\"noreferrer noopener\" target=\"_blank\">MS COCO car damage detection.<\/a><\/p>\n\n\n\n<p id=\"92a7\">This dataset contains 59 train images, 11 validation images, and 8 test images.<\/p>\n\n\n\n<p id=\"673c\">As we can see data is too small. For that, we have used a pre-trained YOLO model on the MS COCO dataset which contains 80 categories. We have replaced the final layers and freezed the rest of the model. Then trained for 100 epochs with data augmentation.<\/p>\n\n\n\n<figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https:\/\/miro.medium.com\/v2\/resize:fit:1400\/1*qNP3D8tHBPf-P3_RemLe4A.png\" alt=\"\"\/><\/figure>\n\n\n\n<p id=\"69e2\">Here in the results, we can there are many overlaps, and the probability is also low. Since training data was very low and the pre-trained model was trained on various 80 kinds of class images, therefore, Model was not able to learn much. We can collect more images and manually annotate them to get better accuracy and results.<\/p>\n\n\n\n<p id=\"c24b\">We can use this damage detection model in Insurance Applications by detecting the damage to the car in an accident which can help users to claim insurance online. And Insurance companies also can save a lot of money since I believe if Machine Learning is not growing business value it is not useful to spend time and money on Machine Learning.<\/p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"bb4d\">Conclusion<\/h2>\n\n\n\n<p id=\"d5dc\">In this blog, we have learned the architecture and working of YOLO algorithms and also seen how YOLO can be used in the industry of Automobiles with Car Damage detection dataset. There are various industries where object detection can be applied such as warehouses, Automated Industries, Healthcare, etc.<\/p>\n\n\n\n<p id=\"5867\">As always, drop me a line in the comments if you have any doubts or can be helpful in any way! \ud83d\ude01<\/p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"bfac\">Further Reading<\/h2>\n\n\n\n<ol>\n<li><a href=\"https:\/\/pjreddie.com\/media\/files\/papers\/YOLOv3.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">YOLO v3: An incremental improvement<\/a><\/li>\n\n\n\n<li><a href=\"https:\/\/arxiv.org\/pdf\/1506.02640.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">You Only Look Once: Unified, Real-Time Object Detection<\/a><\/li>\n<\/ol>\n\n\n\n<p><a href=\"https:\/\/medium.com\/tag\/machine-learning?source=post_page-----7f677cc6ad74---------------machine_learning-----------------\"><\/a><\/p>\n\n\n\n<p><a href=\"https:\/\/medium.com\/tech-blogs-by-nest-digital\/demystifying-data-mesh-9a34ad69108f?source=author_recirc-----7f677cc6ad74----1---------------------26e9a463_7e86_478c_b25a_ca475df1167f-------\"><\/a><\/p>\n","protected":false},"excerpt":{"rendered":"<p>You might have heard of ADAS (Advanced driver assistance systems) in many cars nowadays, which are smart enough to detect the human in front of the car and apply brakes automatically. Have you thought what is the technology behind that? Leading car Manufacturers have stepped in to integrate ADAS into their cars. Existing ADAS technologies [&hellip;]<\/p>\n","protected":false},"author":9,"featured_media":5665,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":{"inline_featured_image":false,"footnotes":"","wds_primary_category":16},"categories":[16],"tags":[35],"blocksy_meta":"","_links":{"self":[{"href":"https:\/\/nestdigital.com\/wp-json\/wp\/v2\/posts\/4508"}],"collection":[{"href":"https:\/\/nestdigital.com\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/nestdigital.com\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/nestdigital.com\/wp-json\/wp\/v2\/users\/9"}],"replies":[{"embeddable":true,"href":"https:\/\/nestdigital.com\/wp-json\/wp\/v2\/comments?post=4508"}],"version-history":[{"count":1,"href":"https:\/\/nestdigital.com\/wp-json\/wp\/v2\/posts\/4508\/revisions"}],"predecessor-version":[{"id":6802,"href":"https:\/\/nestdigital.com\/wp-json\/wp\/v2\/posts\/4508\/revisions\/6802"}],"wp:featuredmedia":[{"embeddable":true,"href":"https:\/\/nestdigital.com\/wp-json\/wp\/v2\/media\/5665"}],"wp:attachment":[{"href":"https:\/\/nestdigital.com\/wp-json\/wp\/v2\/media?parent=4508"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/nestdigital.com\/wp-json\/wp\/v2\/categories?post=4508"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/nestdigital.com\/wp-json\/wp\/v2\/tags?post=4508"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}